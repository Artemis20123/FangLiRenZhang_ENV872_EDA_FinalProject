---
title: 'Forecasting the phytoplankton growth in Mendota Lake'
author: "Group 7: Yuxiang Ren, Kassie Huang, Yu Huan"
date: "Spring 2023 - ENVIRON790 TSA - https://github.com/yuxiang87/YuxiangKassieYu_ENV790_TSA_FinalProject.git"
output:
  pdf_document:
    toc: yes
    includes:
      in_header: header.tex
  html_document:
    toc: yes
    df_print: paged
csl: "apa-6th-edition.csl"
bibliography: reference.bib
link-citations: yes
editor_options:
  chunk_output_type: console
---

```{r packages, include=FALSE}

library(tidyverse);
library(lubridate);
library(here);
library(knitr)
#Load/install required package here
library(lubridate)
library(ggplot2)
library(forecast)  
library(Kendall)
library(tseries)
library(outliers)
library(tidyverse)
library(smooth)
library(kableExtra)

```

## Abstract

Algae bloom, also known as harmful algal blooms (HABs), occurs when there is an excessive growth of phytoplankton in a waterbody. Damage from harmful algal blooms (HABs) significantly impacts the environment and human life in various ways, highlighting the importance of predicting and providing early warnings for HABs.

In this project, three datasets were obtained from the EDI Data Portal with a focus on Mendota Lake (ME) due to its suitability for time series analysis based on its extensive time series data. Cyanophyte biomass was selected as the primary variable of interest, as this division had the highest total biomass and was determined to be the primary contributor to algae bloom outbreaks.

Among the five models evaluated, the SARIMA model demonstrated the highest accuracy. Additional investigation was conducted on how temperature, TN, and TP could improve model performance. We found out that adding temperature and TN slightly improved the accuracy of the original model, but the improvement was very small that the use of autoregression may be a more practical and cost-effective option for real-world forecasting.

\newpage

## Introduction

Algae bloom, also known as harmful algal blooms (HABs), occurs when there is an excessive growth of phytoplankton in a water body. This overgrowth can be caused by various factors, including agriculture, which contributes to the development of HABs in several ways. Agricultural practices such as nutrient runoff from excessive fertilizer use, soil erosion from unsustainable practices, livestock waste management, aquaculture, and inefficient irrigation systems can all lead to increased levels of nitrogen and phosphorus in nearby water bodies [@fertilizer].

Damage from harmful algal blooms (HABs) significantly impacts the environment and human life in various ways. These consequences include creating dead zones where aquatic life cannot survive due to oxygen depletion, disrupting the natural balance of aquatic ecosystems and leading to biodiversity loss, contaminating drinking water supplies with toxins that pose health risks, and affecting recreational water activities [@deadzones]. Moreover, HABs have economic repercussions on industries dependent on clean water, such as commercial fishing, aquaculture, and tourism, leading to financial losses and negatively impacting local economies [@drinkwater].

Therefore, predicting and providing early warnings for harmful algal blooms (HABs) has become increasingly important. Governments in many regions have started to monitor relevant data to establish early warning systems for HAB occurrences. Lakes that adopt water quality-based early warning mechanisms tend to have a greater potential to predict HAB events in advance compared to those relying on biomass or remote sensing images. In this study, we aim to predict algal populations in lakes using time series analysis methods and identify the most suitable forecasting model. By analyzing historical data and examining trends, we hope to better understand the factors influencing algal growth and develop effective strategies for predicting and managing harmful algal blooms.

## Data Processing

Three datasets used in the project were collected from EDI Data Portal, including:

1.  North Temperate Lakes LTER: Phytoplankton - Madison Lakes Area 1995 -- current;[@Phytoplankton_data]
2.  North Temperate Lakes LTER: Physical Limnology of Primary Study Lakes 1981 -- current;
3.  North Temperate Lakes LTER: Chemical Limnology of Primary Study Lakes: Nutrients, pH and Carbon 1981 -- current.

The three files respectively record the water body phytoplankton information, physical information and chemical information of multiple lakes in the Wisconsin range. We analyzed these data at the beginning stage to screen out suitable research subjects, including the target lake, and primary algae responsible for blooms. First, we chose Mendota Lake (ME) for this project, as it has more time measurement data compared to other lakes, which might be more conducive to time series analysis and obtaining more reliable results (Table 1). Second, to obtain information on dominant species that may cause water blooms, we accumulated the biomass of algae from different divisions and considered the algae with the highest total biomass to be the main contributor to water bloom outbreaks. It is worth noting that the original data records the biomass of specific algal species on the observation day. Therefore, to obtain division-level data, we summed the biomass of all species within the same division on the same day to obtain the biomass information for the division. The result shows that the dominant division is Cyanophyta, which is also consistent with other studies (Table 2) [@Mendota1],[@Mendota2].

```{r Data1, echo=FALSE, message=FALSE, warning=FALSE}
phyto <- read.csv(file = "./Data/Phyto_raw.csv")
phyto$sampledate <- ymd(phyto$sampledate)
rawdata <- phyto
site_date_info <- rawdata %>%
  group_by(lakeid) %>%
  summarize(Observation_Count = n_distinct(sampledate)) %>%
  arrange(desc(Observation_Count))
kable(site_date_info, col.names = c("Site", "Observation Date Count"), caption = "Site Information")

```

```{r Data2, echo=FALSE}
biomass_Division <- rawdata %>% group_by(division) %>% 
  mutate(Count = n()) %>% 
summarize('Count' = first(Count),'Total_Biomass' = sum(biomass_conc),'Max_Biomass' = max(biomass_conc, na.rm = TRUE),'Min_Biomass' = min(biomass_conc, na.rm = TRUE),'Mean_Biomass' = mean(biomass_conc, na.rm = TRUE))  %>% arrange(desc(Total_Biomass))

kable(biomass_Division[c(1:5),], 
      col.names = c("Division","Count", "Total Biomass", "Max Biomass", "Min Biomass", "Mean Biomass"),
      caption = "Division level Total Biomass (\\textit{mg/L})")
```

After identifying the target lake and algal division, we cleaned and combined the three data tables. The following are the data cleaning steps:

a.  Integrate the phytoplankton data according to lakeid, sampledate, depth range, and division to obtain the biomass information of each division on the observation day. Then, filter out all data with a lake id of Mendota and a division of Cyanophyta.
b.  Filter out the physical and chemical information of Lake Mendota. Considering that the original data records information at different depths on the same observation day, we calculated the average of all environmental data at depths of 0-8m, which correspond to the depths mentioned in the algae information. It is worth noting that on some dates, the depth of the algae information is 0-2m, and in these cases, we used the average environmental data for 0-2m.
c.  Based on the sampling date and depth range, we combined these data together (Table 3).

```{r data cleanning1,echo=FALSE}
#see more detailed at "Data_wrangling_final1.RMD
load("./Data/ME_rawME_dayI.RDATA")

Table_ME_rawME_dayI_10 <- ME_rawME_dayI[c(1:6),c(1,2,5,6,12,13,14)]
kable(Table_ME_rawME_dayI_10,
      caption = "rawdata")

```

d.  We averaged the data monthly and used the zoo function (na.approx, rule = 2) to fill in NA values. Due to this method is not suitable for filling in NA values at the beginning of data, data before 1996 were removed.
e.  The final dataset includes dates (from 1996 to December 2020), temperature, total nitrogen, total phosphorus, and biomass (Table 4).

```{r data cleanning2, echo=FALSE}
biomass_env <- read.csv(file= "./Data/biomass_Env.csv")

kable(biomass_env[c(1:5),],
      caption = "Final Data")
```

\newpage
## Results

### (1) Auto-regression

Using the full sample from 1996 to 2020, The original plot, Autocorrelation Function (ACF), and the partial autocorrelation function (PACF) plots are shown as follows:

```{r pressure, echo=FALSE}

biomass <- read.csv("./Data/biomass_Env.csv")

biomass_data <- biomass

# Preparing the data - create date object

biomass_data_processed <-
  biomass_data %>%
  mutate( Month = ymd(date) ) %>% 
  arrange(Month)

# Transform to the data frame

biomass_data_frame <- data.frame(Month=biomass_data_processed$Month, 
                          Biomass=biomass_data_processed$Biomass)



# Transform to time series format

# Full sample

ts_biomass_data <- ts(
  biomass_data_frame[1:300,2],
  start=c(year(biomass_data_frame$Month[1]),month(biomass_data_frame$Month[1])),
  frequency=12) 

# Full sample leave 2020 out for accuracy test

ts_biomass <- ts(
  biomass_data_frame[1:288,2],
  start=c(year(biomass_data_frame$Month[1]),month(biomass_data_frame$Month[1])),
  frequency=12)


last_obs <- ts_biomass_data[289:300]



# Plot the time series, ACF, and PACF



TS_Plot <- ggplot(biomass_data_frame, aes(x=Month, y=Biomass)) +
      geom_line() + 
  xlab("Month") + ylab("Total Biomass (g/m2)")

plot(TS_Plot)


#ACF and PACF plots
par(mfrow=c(1,2))
ACF_Plot <- Acf(ts_biomass_data, lag = 40, plot = TRUE,main="")
PACF_Plot <- Pacf(ts_biomass_data, lag = 40, plot = TRUE,main="")

```

It can be seen that there are both clear trend and seasonal components in this plot. The decomposition of the time series is shown as follows:

```{r}
#Plot ts decompose
decompose_biomass_data <- decompose(ts_biomass,"additive")

plot(decompose_biomass_data)
```

Given the complexity of the series, we further try five models to fit the model and conduct forecasting.

The method includes Arithmetic mean, Seasonal naive, SARIMA, SS Exponential smoothing, and BSM (SS with StructTS). We also present their forecast plots and residual analysis plots individually. We first leave the last year which is the year of 2020 out for the purpose of further comparison in the accuracy test.

```{r}
# Model 1: Arithmetic mean
# The meanf() has no holdout option
MEAN_seas <- meanf(y = ts_biomass, h = 12)  
checkresiduals(MEAN_seas)
plot(MEAN_seas)


# Model 2: Seasonal naive
SNAIVE_seas <- snaive(ts_biomass, h=12, holdout=FALSE)
checkresiduals(SNAIVE_seas)
plot(SNAIVE_seas)


# Model 3: SARIMA

SARIMA_autofit <- auto.arima(ts_biomass)
checkresiduals(SARIMA_autofit)

#Generating forecasts

SARIMA_for <- forecast(SARIMA_autofit,h=12)
plot(SARIMA_for)


# Model 4: SS Exponential smoothing
SSES_seas <- es(ts_biomass,model="ZZZ",h=12,holdout=FALSE)
plot(SSES_seas)
checkresiduals(SSES_seas)


# Model 5: SS with StructTS()

SS_seas <- StructTS(ts_biomass,
                    type="BSM",fixed=c(0,0.001,0.3,NA))   #this function has convergence issues
checkresiduals(SS_seas)

#Generating forecasts
SS_for <- forecast(SS_seas,h=12)
plot(SS_for)



```

Based on the residual analysis plots, SARIMA, Exponential smoothing, and BSM shows better distribution in residuals with a near-random distribution and, most points inside the ACF confidence interval without seasonality. However, it is not intuitive which model is the best by simply observing the plots. We further conduct set of rigorous accuracy tests for each model by comparing the forecasted value in the last year which is 2020 with the observed value. The result of the accuracy test is conducted as follows:

```{r}

#Model 1: Arithmetic mean
MEAN_scores <- accuracy(MEAN_seas$mean,last_obs)

#Model 2: Seasonal naive 
SNAIVE_scores <- accuracy(SNAIVE_seas$mean,last_obs)

# Model 3:  SARIMA 
SARIMA_scores <- accuracy(SARIMA_for$mean,last_obs)

# Model 4:  SSES
SSES_scores <- accuracy(SSES_seas$forecast,last_obs)

# Model 5:  BSM 
SS_scores <- accuracy(SS_for$mean,last_obs)


```

To present the accuracy result in a comparable way, I created a compare performance metrics to select the model with the lowest RMSE in Table 5.

```{r}

#Create comparison data frame
seas_scores <- as.data.frame(rbind(MEAN_scores, SNAIVE_scores, SARIMA_scores,SSES_scores,SS_scores))
row.names(seas_scores) <- c("MEAN", "SNAIVE","SARIMA","SSES","BSM")

#choose model with lowest RMSE
best_model_index <- which.min(seas_scores[,"RMSE"])
cat("The best model by RMSE is:", row.names(seas_scores[best_model_index,])) 


kbl(seas_scores, 
      caption = "Forecast Accuracy for Seasonal Data",
      digits = array(5,ncol(seas_scores))) %>%
  kable_styling(full_width = FALSE, position = "center") %>%
  #highlight model with lowest RMSE
  kable_styling(latex_options="striped", stripe_index = which.min(seas_scores[,"RMSE"]))


```

Based on highlighted lowest RMSE in the compare performance metrics, the model with the best fit is the SARIMA model.

To visually compare the result of forecasts using different models, we further jointly plot the forecast generated using five models and compare them with the actual observed value. The plot is shown as follows:

```{r}
autoplot(ts_biomass_data) +
  autolayer(MEAN_seas, PI=FALSE, series="Mean") +
  autolayer(SNAIVE_seas, PI=FALSE, series="Naïve") +
  autolayer(SARIMA_for,PI=FALSE, series="SARIMA") +
  autolayer(SSES_seas$forecast, series="SSES") +
  autolayer(SS_for,PI=FALSE,series="BSM") + 
  xlab("Month") + ylab("Total Biomass (g/m2)") +
  guides(colour=guide_legend(title="Forecast"))


```

From the plot, we can see the SARIMA is the one with the closest forecasted value to the actual observation. If we only plot the actual value and the forecasted value using our outperforming model, SARIMA is shown as follows:

```{r}
autoplot(ts_biomass_data) +

autolayer(SARIMA_for,PI=FALSE, series="SARIMA") +
  xlab("Month") + ylab("Total Biomass (g/m2)") +
  guides(colour=guide_legend(title="Forecast"))

```

Then, we use our selected SARIMA model to conduct the forecast for the year 2021 using the full sample. The residual plot general shows random and most of the values are within the confidence interval of the ACF plot. The parameter of the fitted SARIMA model is ARIMA(0,1,2)(0,0,1). The forecast plot with a confidence interval of 95% for 2021 is shown as follows:

```{r}
# Forecast

SARIMA_autofit_new <- auto.arima(ts_biomass_data)
checkresiduals(SARIMA_autofit_new)

SARIMA_for_new <- forecast(SARIMA_autofit_new,h=12)
plot(SARIMA_for_new)
```

The predicted value for the year 2021 is presented as follows:

```{r}
print(SARIMA_for_new$mean)
```

From the original plot of the biomass at the beginning, it seems to start to show a slightly different pattern since 2010. In order to make sure our forecast is not biased by some sudden changes in the previous old years. To be prudent, we further limit our sample to the recent ten years. We use samples from 2010 to 2020 to predict again. All the procedures are the same as the above full sample analysis only by changing the time span to the recent 10 years.

```{r}
# Change the time span

# Transform to time series format

ts_biomass_data <- ts(
  biomass_data_frame[169:300,2],
  start=c(year(biomass_data_frame$Month[169]),month(biomass_data_frame$Month[169])),
  frequency=12) 

ts_biomass <- ts(
  biomass_data_frame[169:288,2],
  start=c(year(biomass_data_frame$Month[169]),month(biomass_data_frame$Month[169])),
  frequency=12)


last_obs <- ts_biomass_data[121:132]

# Plot the time series, ACF, and PACF



TS_Plot <- ggplot(biomass_data_frame[169:300,], aes(x=Month, y=Biomass)) +
      geom_line() + 
  xlab("Month") + ylab("Total Biomass (g/m2)")

plot(TS_Plot)


#ACF and PACF plots
par(mfrow=c(1,2))
ACF_Plot <- Acf(ts_biomass_data, lag = 40, plot = TRUE,main="")
PACF_Plot <- Pacf(ts_biomass_data, lag = 40, plot = TRUE,main="")

#Plot ts decompose
decompose_biomass_data <- decompose(ts_biomass,"additive")

plot(decompose_biomass_data)

```

The ACF and PACF plot pattern show similar to previous We still use those five models to fit the data. The fitting process and forecast plot is shown as follows:

```{r}
# Model 1: Arithmetic mean
# The meanf() has no holdout option
MEAN_seas <- meanf(y = ts_biomass, h = 12)  
checkresiduals(MEAN_seas)
plot(MEAN_seas)


# Model 2: Seasonal naive
SNAIVE_seas <- snaive(ts_biomass, h=12, holdout=FALSE)
checkresiduals(SNAIVE_seas)
plot(SNAIVE_seas)


# Model 3: SARIMA

SARIMA_autofit <- auto.arima(ts_biomass)
checkresiduals(SARIMA_autofit)

#Generating forecasts
#remember auto.arima does not call the forecast() internally so we need one more step
SARIMA_for <- forecast(SARIMA_autofit,h=12)
plot(SARIMA_for)


# Model 4: SS Exponential smoothing
SSES_seas <- es(ts_biomass,model="ZZZ",h=12,holdout=FALSE)
plot(SSES_seas)
checkresiduals(SSES_seas)


# Model 5: SS with StructTS()

SS_seas <- StructTS(ts_biomass,
                    type="BSM",fixed=c(0,0.001,0.3,NA))   #this function has convergence issues
checkresiduals(SS_seas)

#Generating forecasts
# StructTS() does not call the forecast() internally so we need one more step
SS_for <- forecast(SS_seas,h=12)
plot(SS_for)



#Model 1: Arithmetic mean
MEAN_scores <- accuracy(MEAN_seas$mean,last_obs)  #store the performance metrics

#Model 2: Seasonal naive 
SNAIVE_scores <- accuracy(SNAIVE_seas$mean,last_obs)

# Model 3:  SARIMA 
SARIMA_scores <- accuracy(SARIMA_for$mean,last_obs)

# Model 4:  SSES
SSES_scores <- accuracy(SSES_seas$forecast,last_obs)

# Model 5:  BSM 
SS_scores <- accuracy(SS_for$mean,last_obs)


#Create comparison data frame
seas_scores <- as.data.frame(rbind(MEAN_scores, SNAIVE_scores, SARIMA_scores,SSES_scores,SS_scores))
row.names(seas_scores) <- c("MEAN", "SNAIVE","SARIMA","SSES","BSM")

#choose model with lowest RMSE
best_model_index <- which.min(seas_scores[,"RMSE"])
cat("The best model by RMSE is:", row.names(seas_scores[best_model_index,])) 


kbl(seas_scores, 
      caption = "Forecast Accuracy for Seasonal Data",
      digits = array(5,ncol(seas_scores))) %>%
  kable_styling(full_width = FALSE, position = "center") %>%
  #highlight model with lowest RMSE
  kable_styling(latex_options="striped", stripe_index = which.min(seas_scores[,"RMSE"]))






```

Based on the compare performance metrics in Table 6, the SARIMA still shows the best fit with the lowest RMSE value which is consistent with the exercise using the full sample. To visually compare the result of forecasts using different models, we further jointly plot the forecast generated using five models and compare them with the actual observed value, and again also isolate the SARIMA forecast plot alone with the actual values. The plots are shown as follows:

```{r}
autoplot(ts_biomass_data) +
  autolayer(MEAN_seas, PI=FALSE, series="Mean") +
  autolayer(SNAIVE_seas, PI=FALSE, series="Naïve") +
  autolayer(SARIMA_for,PI=FALSE, series="SARIMA") +
  autolayer(SSES_seas$forecast, series="SSES") +
  autolayer(SS_for,PI=FALSE,series="BSM") + 
  xlab("Month") + ylab("Total Biomass (g/m2)") +
  guides(colour=guide_legend(title="Forecast"))



autoplot(ts_biomass_data) +

autolayer(SARIMA_for,PI=FALSE, series="SARIMA") +
  xlab("Month") + ylab("Total Biomass (g/m2)") +
  guides(colour=guide_legend(title="Forecast"))



```

Using the SARIMA model to conduct the forecast for the year 2021 using the full sample. The residual general shows random and most of the values are within the confidence interval of the ACF plot. The parameter for the fitted SARIMA model is ARIMA(1,0,0)(1,0,0). The forecast plot with a confidence interval of 95% for 2021 is shown as follows:

```{r}
# Forecast

SARIMA_autofit_new <- auto.arima(ts_biomass_data)
checkresiduals(SARIMA_autofit_new)

SARIMA_for_new <- forecast(SARIMA_autofit_new,h=12)
plot(SARIMA_for_new)
```

The predicted value for the year 2021 using recent ten-year data from 2010 is presented as follows:

```{r}
print(SARIMA_for_new$mean)

```

Therefore, for the single variable time series forecast, we use the SARIMA model to fit which is robust even change our time span to the recent ten years. We get our predicted value from SARIMA in a consistent manner.

\newpage

### (2) Exogenous Variables: Temperature, TN and TP

Other than biomass itself, that there may be exogenous variables that also influence phytoplankton biomass, and incorporating these variables into the model could potentially improve our ability to forecast the phytoplankton biomass. Therefore, we searched the existing literature to identify key variables.

As shown in the table 7 below, it appears that temperature, nitrogen, and phosphorus appear throughout the literature. In terms of the mechanism by which they affect phytoplankton biomass, the three variables fall into two groups: First, temperature affects the metabolic rates of organisms. As temperature increases, the metabolic rates of phytoplankton and their predators increase at different rates and reach their growth optima at different times. Second, phytoplankton growth is often limited by nutrient availability. Nitrogen (N) and phosphorus (P) are the two such nutrients, so increasing TN and TP could lead to increased phytoplankton growth rates and hence their biomass.

| Author                                | Key findings                                                                                                                                                                                                                              |
|---------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Yuan and Pollard [@Yuan2018]          | The mean biomass of zooplankton individuals was best predicted by physical lake characteristics such as geographic location, mean annual temperature, affecting the relationship between zooplankton (Z) and phytoplankton (P) biomasses. |
| Borics et al. [@Borics2013]           | By incorporating lake depth, TP, TN and lake use as independent and Chl-a as dependent variables into different models, the predictive models explained 50% of the variance.                                                              |
| Cai et al. [@Cai2012]                 | Multiple stepwise linear regression revealed that EAWT, dissolved total phosphorus (DTP), and TP explained 99.2% of the variation of Chl-a in Meiliang Bay.                                                                               |
| Burgmer and Hillebrand [@Burgmer2011] | Altered temperature regimes strongly aﬀected algal biomass and diversity by interdependently altering competitive and consumer interactions.                                                                                              |

: **Literature Review**

Therefore, we added the three variables individually to the best performing model, i.e. SARIMA, to see if the model performance would be improved accordingly. Table 8 shows the forecast accuracy of adding each explanatory variables, where the first row shows the accuracy of the original SARIMA model, and the following rows show the accuracy of the new models with one exogenous variable added.

According to Table 8, in terms of Mean Error (ME), none of the three new models improved the performance, but worsened it. On the other hand, adding temperature helped to slightly improve the model's accuracy in all other metrics (RMSE, MAE, MPE, and MAPE), and adding TN slightly improved the model's accuracy in terms of MPE and MAPE.

```{r Ren_TSA_data, include=FALSE}
biomass_env
Ren_ts_biomass <- ts(
  biomass_env[c(1:288),5],
  start=c(1996,01),
  frequency=12) 
Ren_ts_T <- ts(
  biomass_env[c(1:288),2],
  start=c(1996,01),
  frequency=12) 
future_T <- biomass_env[c(289:300),2]
Ren_ts_TN <- ts(
  biomass_env[c(1:288),3],
  start=c(1996,01),
  frequency=12) 
future_TN <- biomass_env[c(289:300),3]
Ren_ts_TP <- ts(
  biomass_env[c(1:288),3],
  start=c(1996,01),
  frequency=12) 
future_TP <- biomass_env[c(289:300),4]
```

```{r Ren_bio_env_autoARIMA, message=FALSE, warning=FALSE, include=FALSE}
#arima_ren
arima_ren <- auto.arima(Ren_ts_biomass, seasonal = TRUE)
forecast_biomass_Ren <- forecast(arima_ren, h = 12)
#biomass~T
arima_biomass_T <- auto.arima(Ren_ts_biomass, xreg = Ren_ts_T, seasonal = TRUE)
forecast_biomass_T <- forecast(arima_biomass_T, h = 12, xreg = future_T)
#biomass~TN
arima_biomass_TN <- auto.arima(Ren_ts_biomass, xreg = Ren_ts_TN, seasonal = TRUE)
forecast_biomass_TN <- forecast(arima_biomass_TN, h = 12, xreg = future_TN)
#biomass~TP
arima_biomass_TP <- auto.arima(Ren_ts_biomass, xreg = Ren_ts_TP, seasonal = TRUE)
forecast_biomass_TP <- forecast(arima_biomass_TP, h = 12, xreg = future_TP)
```

```{r Ren_accuarcy, echo=FALSE, message=FALSE, warning=FALSE}
Ren_auto <- accuracy(forecast_biomass_Ren$mean,last_obs) 
Ren_biomassT <- accuracy(forecast_biomass_T$mean,last_obs) 
Ren_biomassTN <- accuracy(forecast_biomass_TN$mean,last_obs) 
Ren_biomassTP <- accuracy(forecast_biomass_TP$mean,last_obs) 

Ren_scores <- as.data.frame(rbind(Ren_auto, Ren_biomassT, Ren_biomassTN,Ren_biomassTP))
row.names(Ren_scores) <- c("SARIMA", "Temperature","TN","TP")
#Table
kbl(Ren_scores, 
      caption = "Forecast Accuracy for Explanatory Variable",
      digits = array(4,ncol(Ren_scores))) %>%
  kable_styling(full_width = FALSE, position = "center") %>%
  #highlight model with lowest RMSE
  kable_styling(latex_options="striped", stripe_index = which.min(seas_scores[,"RMSE"]))
#figure
autoplot(ts_biomass_data) +
  autolayer(forecast_biomass_Ren$mean, PI=FALSE, series="SARIMA") +
  autolayer(forecast_biomass_T$mean, PI=FALSE, series="Temperature") +
  autolayer(forecast_biomass_TN$mean,PI=FALSE, series="TN") +
  autolayer(forecast_biomass_TP$mean, series="TP") + 
  xlab("Year") + ylab("Total Biomass (g/m2)") +
  guides(colour=guide_legend(title="Forecast"))

```

Figure above shows forecast results of different models. Consistent with the accuracy metrics, temperature and TN improved the performance of the original SARIMA model, especially its ability to forecast the peak in 2020. Also, adding temperature improved the prediction of low values. In contrast, adding TP significantly worsened the model's overall accuracy, as it only focuses on the peaks.

\newpage

## Discussion

Of the five different models we tried, the SARIMA model performed best in terms of accuracy. To further explore how exogenous variables could improve the performance of the model, we tried adding temperature, TN, and TP to the model, and temperature and TN slightly improved the performance of the original model. Specifically, adding temperature improved the original model's ability to handle extreme variation, as reflected by a lower RMSE.

However, all of the models we examined have relatively high (absolute value) MPE and MAPE. A possible explanation could be that many of the actual values of phytoplankton biomass are close to zero. As a result, the MPE and MAPE can go very high as they calculate the relative error of a near-zero actual value.

There are several outstanding limitations of our study. First, we only added one exogenous variable at a time, ignoring the combination of different exogenous variables could produce a better forecast. Second, the data of the exogenous variables we used in the forecast is the actual observed data rather than the forecast from their historical level. A major obstacle here was that our exogenous variable contained too many NAs which made it difficult for any model to forecast.

Therefore, the improvement from adding exogenous variables could be significantly smaller than our results, given the difficulty in accurately forecasting these exogenous variables. From our perspective, given that improvement is still quite subtle even using the real observed data, sticking to auto-regression may be a simpler and more economical option in real-world forecasting.

***Individual contributions to this report***

*Abstract: Kassie*

*Introduction: Yuxiang*

*Data Processing: Yuxiang*

*Result-Autoregression: Yu (coding), Yuxiang (formatting and git support)*

*Result-Exogenous variables: Yuxiang (coding), Kassie (literature & writing)*

*Discussion: Kassie*

*Reference (and knitting, etc.): Yuxiang*
\newpage
## Reference
